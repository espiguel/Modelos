{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: pdf2image in /opt/conda/lib/python3.7/site-packages (1.16.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from pdf2image) (9.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys  #https://www.quora.com/What-does-import-sys-mean-in-Python\n",
    "#sys es uno de los modulos disponibles para importar\n",
    "# sys module: conjunto de funciones que brinda la info de como el python script interactua con el host system\n",
    "\n",
    "# sys modules has information about :\n",
    "#    1. version of Python is running\n",
    "#    2. The path to the Python executable that is executing your script\n",
    "#    3. The command line options used to execute your script\n",
    "#    4. Any Python specific flags that have been set\n",
    "#    5. Information about floating point values and their representation.\n",
    "#    6. functions which can set what happens after each python instruction.\n",
    "#    7. function to cleanly exit the Python interpreter.\n",
    "\n",
    "#If your code has import sys - then it can use the functionality and data in it by using terms such as :\n",
    "\n",
    "# sys.argv: A list of strings which is the command line used to execute the script separated by spaces.\n",
    "# sys.exit(): Exit Python cleanly\n",
    "# sys.version: The Python version string\n",
    "\n",
    "!conda install --yes --prefix {sys.prefix} -c conda-forge poppler\n",
    "!pip install pdf2image\n",
    "\n",
    "import boto3 # --> permite usar bucket S3!!!\n",
    "#Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python,\n",
    "# que permite a los Python DEV escribir software que use los servicios de: Amazon S3 and Amazon EC2.\n",
    "import io # --> a web-based platform for extracting data from websites without writing any code\n",
    "import json\n",
    "#El formato JSON se utiliza para estructurar datos en forma de texto y permite el intercambio de información \n",
    "#entre aplicaciones de manera sencilla, liviana y rápida\n",
    "#Los datos en formato JSON pueden ser utilizados por prácticamente todos los lenguajes de programación \n",
    "#(como Java, C#, C, C++, PHP, JavaScript, Python, etc.)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re #--> Operaciones con EXPRSIONES REGULARES\n",
    "import requests #--> La librería para hacer peticiones http en Python\n",
    "import logging #--> logging de Python registra errores de código simples y genera un mensaje\n",
    "import time\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pdf2image\n",
    "import requests\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'n2-data-certification-model-deploy-dev-endpoint'  # URL's que reciben o retornan información de un Web API se les llama endpoints \n",
    "MODEL_VERSION = '13'\n",
    "MAX_LABELS = 200 #LABEL: etiqueta para un elemento en una interfaz de usuario\n",
    "MIN_CONFIDENCE = 5 #al menos 5% --> esto responde a la cantidad MINIMA de \"confianza\" en la que el label esta en la imagen\n",
    "FEATURES = ['Text', 'Handwriting', 'Symbol', 'Number', 'Paper', 'Document', 'Apparel', 'Clothing', 'Signature', 'Autograph', \n",
    "            'Animal', 'Letter', 'Alphabet', 'Page', 'Plant', 'Accessories', 'Accessory', 'Food', 'Envelope', 'Beverage', \n",
    "            'Drink', 'Electronics', 'Musical Instrument', 'Word', 'File Binder', 'Alcohol', 'Mail', 'Footwear', 'Invertebrate', 'Furniture', \n",
    "            'QR Code', 'Gray', 'Calligraphy', 'Jewelry', 'Broom']\n",
    "#feature is a measurable property of the object you're trying to analyze. \n",
    "#In datasets, features appear as columns\n",
    "\n",
    "client_rekognition = boto3.client(\"rekognition\", 'us-east-1') #https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#client\n",
    "#class rekognition.client --> viene con los objetos (funciones: DetectFaces,DetectLabels,DetectText)\n",
    "client_sagemaker = boto3.client(\"runtime.sagemaker\")\n",
    "client_s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64 \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf prueba en base 64\n",
    "url_s3='https://stage-upload-management-service.s3.amazonaws.com/384ca7bc-728f-4bfb-9cbf-99e70c69d8ea-AUTOREGISTRO.docx.pdf'\n",
    "\n",
    "response = requests.get(url_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(in_64.decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdf;']\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "in_64=response.content.decode(\"utf-8\")\n",
    "result = re.sub(r\"data.+base64.\\b\",  ' ',  in_64)\n",
    "\n",
    "    \n",
    "x = re.findall((r\"(pdf;|png;|jpeg;|bmp;)\\b\") , in_64) #findall devuelve lista con los elementos encontrados\n",
    "#uso el ; al final de pdf,png,etc pues necesito garantizar que en el resto del .txt NO exista otras 3 letras que en realidad no representen un tipo de formato de archivo\n",
    "print(x)\n",
    "\n",
    "if (\"pdf;\" in x):\n",
    "    with open('pdf_file.pdf', 'wb') as theFile:\n",
    "        theFile.write(base64.b64decode(result))\n",
    "        print(type(base64.b64decode(result)))\n",
    "elif(\"png;\" in x):\n",
    "    with open('file_png.png', 'wb') as theFile:\n",
    "        theFile.write(base64.b64decode(result))\n",
    "        print(type(base64.b64decode(result)))\n",
    "elif(\"jpeg;\" in x):\n",
    "    with open('file_jpg.jpg', 'wb') as theFile:\n",
    "        theFile.write(base64.b64decode(result))\n",
    "        print(type(base64.b64decode(result)))\n",
    "elif(\"bmp;\" in x):\n",
    "    with open('file_bmp.bmp', 'wb') as theFile:\n",
    "        theFile.write(base64.b64decode(result))\n",
    "        print(type(base64.b64decode(result)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Puesto que el usuario puede cargar libremente el formato del certificado\n",
    "# detect_labels_from pdf --> aplica cuando carga PDF\n",
    "# detect_labels_from bytes --> - - - OTRO FORMATO\n",
    "#\n",
    "# funcion detect_labels --> engloba a los 2\n",
    "\n",
    "# A tener en cuenta: el usuario puede cargar HASTA 3 archivos distintos como certificados\n",
    "# Sin embargo, este modelo SOLO evalua la primer pagina de los mismos\n",
    "\n",
    "def detect_labels_from_pdf(client, pdf_file, max_labels, min_confidence):\n",
    "    response = requests.get(pdf_file, timeout=30)  #.get() method sends a GET request to the specified url\n",
    "    #timeout= seconds to wait for the client to make a connection/send a response\n",
    "    pages = pdf2image.convert_from_bytes(response.content, dpi=300)\n",
    "    #convert_from_bytes(pdf.read()) --> convierte pdf en imagen\n",
    "    #pdf.read() --> en este caso se RESPONSE.CONTENT\n",
    "    img = pages[0].convert('RGB') # PAGES[0] \n",
    "    buf = io.BytesIO() #instancia vacía que dsps la cargo con el contenido de la siguiente linea de codigo \n",
    "    img.save(buf, format='JPEG')\n",
    "    byte_im = buf.getvalue()\n",
    "    return client.detect_labels(Image={'Bytes': byte_im}, MaxLabels=max_labels, MinConfidence=min_confidence)\n",
    "    #devuelve un DICCIONARIO con los labels y sus parametros:\n",
    "    # {'Labels':\n",
    "    #    [{'Name': 'QR Code', \n",
    "    #      'Confidence': 91.76808166503906, 'Instances': [], 'Parents': []}, etc \n",
    "    \n",
    "def detect_labels_from_bytes(client, file, max_labels, min_confidence):\n",
    "    #cuando el documento no es pdf\n",
    "    response = requests.get(file)\n",
    "    \n",
    "    return client.detect_labels(Image={'Bytes': response.content}, MaxLabels=max_labels, MinConfidence=min_confidence)\n",
    "\n",
    "#Este caso engloba los 2 casos anteriores!: cuando el usuario carga el certif como PDF o como OTRO FORMATO\n",
    "def detect_labels(client, file, max_labels, min_confidence):\n",
    "    try:\n",
    "        file_extension = file.split('.')[-1].lower() #.split()[-1] pues ahi queda el FORMATO (.pdf/.JPEG/..)\n",
    "        if file_extension == 'pdf':\n",
    "            return detect_labels_from_pdf(client, file, max_labels, min_confidence)\n",
    "        else:\n",
    "            return detect_labels_from_bytes(client, file, max_labels, min_confidence)\n",
    "    except: #caso que no pueda levantar el archivo por formato incompatible --> que tire un error\n",
    "        logging.error(\"Exception occurred\", exc_info=True)\n",
    "        return {}\n",
    "    \n",
    "def query_endpoint(encoded_tabular_data, endpoint_name, content_type='text/csv'):\n",
    "    response = client_sagemaker.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_tabular_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    predicted_probabilities = model_predictions[\"probabilities\"]\n",
    "    return np.array(predicted_probabilities)\n",
    "\n",
    "def save_rekognition_labels(id_image, response):\n",
    "    if (os.getenv('BUCKET_REKOGNITION_LABELS', default = None) is not None) & (os.getenv('FOLDER_REKOGNITION_LABELS', default = None) is not None):\n",
    "        try:\n",
    "            s3object = client_s3.Object(os.getenv('BUCKET_REKOGNITION_LABELS'), \n",
    "                                                '{}/image_{}.json'.format(os.getenv('FOLDER_REKOGNITION_LABELS'), id_image))\n",
    "            s3object.put(Body=(bytes(json.dumps(response).encode('UTF-8'))))\n",
    "        except:\n",
    "            logging.error(\"Exception occurred\", exc_info=True)\n",
    "\n",
    "def get_predictions(data_image):\n",
    "    labels = [\"Rechazado\", \"Aprobado\"]\n",
    "    try:\n",
    "        logging.info(f'get_predictions id_image: {data_image[\"id_image\"]}')\n",
    "        # Call rekognition\n",
    "        logging.info(f'call rekognition id_image: {data_image[\"id_image\"]}')\n",
    "        response = detect_labels(client_rekognition, data_image['url_image'], max_labels=MAX_LABELS, min_confidence=MIN_CONFIDENCE)\n",
    "        # Save rekognition features\n",
    "        logging.info(f'save rekognition features id_image: {data_image[\"id_image\"]}')\n",
    "        save_rekognition_labels(id_image=data_image['id_image'], response=response)\n",
    "        # Create dataframe\n",
    "        logging.info(f'create dataframe id_image: {data_image[\"id_image\"]}')\n",
    "        df = pd.DataFrame([{i['Name']:i['Confidence'] for i in response['Labels']}])\n",
    "        columns = df.columns.tolist()\n",
    "        empty_columns = list(set(FEATURES) - set(columns))\n",
    "        for column in empty_columns:\n",
    "            df[column] = 0\n",
    "        df['file_is_pdf'] = int(data_image['url_image'].split('.')[-1].lower() == 'pdf')\n",
    "        # Endpoint request\n",
    "        logging.info(f'call sagemaker id_image: {data_image[\"id_image\"]}')\n",
    "        query_response_batch = query_endpoint(\n",
    "            df[['file_is_pdf'] + FEATURES].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "            endpoint_name=ENDPOINT_NAME\n",
    "        )\n",
    "        predict_prob = np.concatenate(parse_response(query_response_batch), axis=0)\n",
    "        logging.info(f'response id_image: {data_image[\"id_image\"]}')\n",
    "        return {\n",
    "            \"id_image\": data_image[\"id_image\"],\n",
    "            \"url_image\": data_image[\"url_image\"],\n",
    "            \"score\": predict_prob[1],\n",
    "            \"prediction_label\": labels[np.argmax(predict_prob)],\n",
    "            \"model_version_cla\": MODEL_VERSION,\n",
    "            \"end_point\": ENDPOINT_NAME,\n",
    "            \"prediction_status\": \"Ok\"\n",
    "        }\n",
    "    except Exception as err:\n",
    "        logging.error(\"Exception occurred\", exc_info=True)\n",
    "        return {\n",
    "            \"id_image\": data_image[\"id_image\"],\n",
    "            \"url_image\": data_image[\"url_image\"],\n",
    "            \"score\": 0,\n",
    "            \"prediction_label\": \"None\",\n",
    "            \"model_version_cla\": MODEL_VERSION,\n",
    "            \"end_point\": ENDPOINT_NAME,\n",
    "            \"prediction_status\": format(err)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-141-ba128e612e2c>\", line 38, in detect_labels\n",
      "    return detect_labels_from_pdf(client, file, max_labels, min_confidence)\n",
      "  File \"<ipython-input-141-ba128e612e2c>\", line 14, in detect_labels_from_pdf\n",
      "    pages = pdf2image.convert_from_bytes(response.content, dpi=300)\n",
      "AttributeError: 'str' object has no attribute 'content'\n",
      "ERROR:root:Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-141-ba128e612e2c>\", line 77, in get_predictions\n",
      "    df = pd.DataFrame([{i['Name']:i['Confidence'] for i in response['Labels']}])\n",
      "KeyError: 'Labels'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id_image': 2879,\n",
       " 'url_image': '/MIA/Modelo de certificados/pdf_file.pdf',\n",
       " 'score': 0,\n",
       " 'prediction_label': 'None',\n",
       " 'model_version_cla': '13',\n",
       " 'end_point': 'n2-data-certification-model-deploy-dev-endpoint',\n",
       " 'prediction_status': \"'Labels'\"}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_predictions(data_image={'id_image':2879,\n",
    "#                            \"url_image\": \"https://prod-gcba-us-east-1-upload.s3.amazonaws.com/us-east-1%3Aa55bc7d5-0df0-4f0d-a6ea-8657da1ebb1b/us-east-1%3Aa28bffa3-7707-461b-9265-cfacc6829d9a/certificates/1617395950/UMA.PDF\"})\n",
    "\n",
    "get_predictions(data_image={'id_image':2879,\n",
    "                            \"url_image\": \"/MIA/Modelo de certificados/pdf_file.pdf\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_image={'id_image':2879,\n",
    "#            \"url_image\": \"https://stage-upload-management-service.s3.amazonaws.com/384ca7bc-728f-4bfb-9cbf-99e70c69d8ea-AUTOREGISTRO.docx.pdf\"}\n",
    "\n",
    "\n",
    "data_image={'id_image':2879,\n",
    "            \"url_image\": \"MIA/Modelo de certificados/pdf_file.pdf\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_image': 2879, 'url_image': 'MIA/Modelo de certificados/pdf_file.pdf'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-141-ba128e612e2c>\", line 38, in detect_labels\n",
      "    return detect_labels_from_pdf(client, file, max_labels, min_confidence)\n",
      "  File \"<ipython-input-141-ba128e612e2c>\", line 14, in detect_labels_from_pdf\n",
      "    pages = pdf2image.convert_from_bytes(response.content, dpi=300)\n",
      "AttributeError: 'str' object has no attribute 'content'\n"
     ]
    }
   ],
   "source": [
    "response = detect_labels(client_rekognition, data_image['url_image'], max_labels=MAX_LABELS, min_confidence=MIN_CONFIDENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-123e3199bc45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Confidence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Labels'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([{i['Name']:i['Confidence'] for i in response['Labels']}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-0812797d2716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mempty_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mempty_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_is_pdf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "columns = df.columns.tolist()\n",
    "empty_columns = list(set(FEATURES) - set(columns))\n",
    "for column in empty_columns:\n",
    "    df[column] = 0\n",
    "df['file_is_pdf'] = int(data_image['url_image'].split('.')[-1].lower() == 'pdf')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-9b2b7d663255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_is_pdf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFEATURES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#file_is_pdf --> 0 si no es pdf/1 si es pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# FEATURES --> tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[['file_is_pdf'] + FEATURES]\n",
    "#file_is_pdf --> 0 si no es pdf/1 si es pdf\n",
    "# FEATURES --> tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response_batch = query_endpoint(\n",
    "    df[['file_is_pdf'] + FEATURES].to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    endpoint_name=ENDPOINT_NAME\n",
    ")\n",
    "predict_prob = np.concatenate(parse_response(query_response_batch), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 repos: rekognition/conexion a sagemaker\n",
    "#ramas: dev/stage/qa/prod(=master por default)\n",
    "#uell-data-rekognition-tags\n",
    "#uell-data-model-images-classification\n",
    "\n",
    "#2do paso: levantar instancia de rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
